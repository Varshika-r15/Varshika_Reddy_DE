{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\nspark = SparkSession.builder \\\n                    .appName('SparkByExamples.com') \\\n                    .getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"35e6cb71-bdbc-4630-9f25-e4e0f6f84acb","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["data = [('James','Smith','M',3000),\n  ('Anna','Rose','F',4100),\n  ('Robert','Williams','M',6200), \n]\n\ncolumns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\ndf = spark.createDataFrame(data=data, schema = columns)\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"af6e493e-ff87-4f56-9a24-9657e855703e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+--------+------+------+\n|firstname|lastname|gender|salary|\n+---------+--------+------+------+\n|    James|   Smith|     M|  3000|\n|     Anna|    Rose|     F|  4100|\n|   Robert|Williams|     M|  6200|\n+---------+--------+------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["if 'salary1' not in df.columns:\n    print(\"aa\")\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6aa17305-c297-41ba-a39e-c3a0dd7ec7d3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["aa\n"]}],"execution_count":0},{"cell_type":"code","source":["# Add new constanct column\nfrom pyspark.sql.functions import lit\ndf.withColumn(\"bonus_percent\", lit(0.3)) \\\n  .show()\n  \n#Add column from existing column\ndf.withColumn(\"bonus_amount\", df.salary*0.3) \\\n  .show()\n\n#Add column by concatinating existing columns\nfrom pyspark.sql.functions import concat_ws\ndf.withColumn(\"name\", concat_ws(\",\",\"firstname\",'lastname')) \\\n  .show()\n\n#Add current date\nfrom pyspark.sql.functions import current_date\ndf.withColumn(\"current_date\", current_date()) \\\n  .show()\n\nfrom pyspark.sql.functions import when\ndf.withColumn(\"grade\", \\\n   when((df.salary < 4000), lit(\"A\")) \\\n     .when((df.salary >= 4000) & (df.salary <= 5000), lit(\"B\")) \\\n     .otherwise(lit(\"C\")) \\\n  ).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b6ace6b8-d896-442d-b2bb-bd08eadaeb69","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+--------+------+------+-------------+\n|firstname|lastname|gender|salary|bonus_percent|\n+---------+--------+------+------+-------------+\n|    James|   Smith|     M|  3000|          0.3|\n|     Anna|    Rose|     F|  4100|          0.3|\n|   Robert|Williams|     M|  6200|          0.3|\n+---------+--------+------+------+-------------+\n\n+---------+--------+------+------+------------+\n|firstname|lastname|gender|salary|bonus_amount|\n+---------+--------+------+------+------------+\n|    James|   Smith|     M|  3000|       900.0|\n|     Anna|    Rose|     F|  4100|      1230.0|\n|   Robert|Williams|     M|  6200|      1860.0|\n+---------+--------+------+------+------------+\n\n+---------+--------+------+------+---------------+\n|firstname|lastname|gender|salary|           name|\n+---------+--------+------+------+---------------+\n|    James|   Smith|     M|  3000|    James,Smith|\n|     Anna|    Rose|     F|  4100|      Anna,Rose|\n|   Robert|Williams|     M|  6200|Robert,Williams|\n+---------+--------+------+------+---------------+\n\n+---------+--------+------+------+------------+\n|firstname|lastname|gender|salary|current_date|\n+---------+--------+------+------+------------+\n|    James|   Smith|     M|  3000|  2023-06-12|\n|     Anna|    Rose|     F|  4100|  2023-06-12|\n|   Robert|Williams|     M|  6200|  2023-06-12|\n+---------+--------+------+------+------------+\n\n+---------+--------+------+------+-----+\n|firstname|lastname|gender|salary|grade|\n+---------+--------+------+------+-----+\n|    James|   Smith|     M|  3000|    A|\n|     Anna|    Rose|     F|  4100|    B|\n|   Robert|Williams|     M|  6200|    C|\n+---------+--------+------+------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["\n# Add column using select\ndf.select(\"firstname\",\"salary\", lit(0.3).alias(\"bonus\")).show()\ndf.select(\"firstname\",\"salary\", lit(df.salary * 0.3).alias(\"bonus_amount\")).show()\ndf.select(\"firstname\",\"salary\", current_date().alias(\"today_date\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ed9e23c5-3eb1-41a1-8490-41502086ea4c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+------+-----+\n|firstname|salary|bonus|\n+---------+------+-----+\n|    James|  3000|  0.3|\n|     Anna|  4100|  0.3|\n|   Robert|  6200|  0.3|\n+---------+------+-----+\n\n+---------+------+------------+\n|firstname|salary|bonus_amount|\n+---------+------+------------+\n|    James|  3000|       900.0|\n|     Anna|  4100|      1230.0|\n|   Robert|  6200|      1860.0|\n+---------+------+------------+\n\n+---------+------+----------+\n|firstname|salary|today_date|\n+---------+------+----------+\n|    James|  3000|2023-06-12|\n|     Anna|  4100|2023-06-12|\n|   Robert|  6200|2023-06-12|\n+---------+------+----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Add columns using SQL\ndf.createOrReplaceTempView(\"PER\")\nspark.sql(\"select firstname,salary, '0.3' as bonus from PER\").show()\nspark.sql(\"select firstname,salary, salary * 0.3 as bonus_amount from PER\").show()\nspark.sql(\"select firstname,salary, current_date() as today_date from PER\").show()\nspark.sql(\"select firstname,salary, \" +\n          \"case salary when salary < 4000 then 'A' \"+\n          \"else 'B' END as grade from PER\").show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"dc090be7-5fa2-4884-ba11-f0d96df09305","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+------+-----+\n|firstname|salary|bonus|\n+---------+------+-----+\n|    James|  3000|  0.3|\n|     Anna|  4100|  0.3|\n|   Robert|  6200|  0.3|\n+---------+------+-----+\n\n+---------+------+------------+\n|firstname|salary|bonus_amount|\n+---------+------+------------+\n|    James|  3000|       900.0|\n|     Anna|  4100|      1230.0|\n|   Robert|  6200|      1860.0|\n+---------+------+------------+\n\n+---------+------+----------+\n|firstname|salary|today_date|\n+---------+------+----------+\n|    James|  3000|2023-06-12|\n|     Anna|  4100|2023-06-12|\n|   Robert|  6200|2023-06-12|\n+---------+------+----------+\n\n+---------+------+-----+\n|firstname|salary|grade|\n+---------+------+-----+\n|    James|  3000|    B|\n|     Anna|  4100|    B|\n|   Robert|  6200|    B|\n+---------+------+-----+\n\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-add-new-column 2023-06-11 20:13:20","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
