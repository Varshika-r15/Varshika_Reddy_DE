{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8da23039-c960-44a7-8b1a-d1d5d8eeccf2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dataDictionary = [\n        ('James',{'hair':'black','eye':'brown'}),\n        ('Michael',{'hair':'brown','eye':None}),\n        ('Robert',{'hair':'red','eye':'black'}),\n        ('Washington',{'hair':'grey','eye':'grey'}),\n        ('Jefferson',{'hair':'brown','eye':''})\n        ]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6319b1f5-4c21-44f4-bfe1-6de5b633e4ad","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Using StructType schema\nfrom pyspark.sql.types import StructField, StructType, StringType, MapType\nschema = StructType([\n    StructField('name', StringType(), True),\n    StructField('properties', MapType(StringType(),StringType()),True)\n])\ndf = spark.createDataFrame(data=dataDictionary, schema = schema)\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d2e2fb78-7686-4820-9af3-c8efaf1300ed","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- name: string (nullable = true)\n |-- properties: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+----------+-----------------------------+\n|name      |properties                   |\n+----------+-----------------------------+\n|James     |{eye -> brown, hair -> black}|\n|Michael   |{eye -> null, hair -> brown} |\n|Robert    |{eye -> black, hair -> red}  |\n|Washington|{eye -> grey, hair -> grey}  |\n|Jefferson |{eye -> , hair -> brown}     |\n+----------+-----------------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df3=df.rdd.map(lambda x: \\\n    (x.name,x.properties[\"hair\"],x.properties[\"eye\"])) \\\n    .toDF([\"name\",\"hair\",\"eye\"])\ndf3.printSchema()\ndf3.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"489354af-a095-4c03-89bd-c7da2494d033","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- name: string (nullable = true)\n |-- hair: string (nullable = true)\n |-- eye: string (nullable = true)\n\n+----------+-----+-----+\n|      name| hair|  eye|\n+----------+-----+-----+\n|     James|black|brown|\n|   Michael|brown| null|\n|    Robert|  red|black|\n|Washington| grey| grey|\n| Jefferson|brown|     |\n+----------+-----+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.withColumn(\"hair\",df.properties.getItem(\"hair\")) \\\n  .withColumn(\"eye\",df.properties.getItem(\"eye\")) \\\n  .drop(\"properties\") \\\n  .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a458150c-cc67-4f48-bead-2f9b687c480d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+-----+-----+\n|      name| hair|  eye|\n+----------+-----+-----+\n|     James|black|brown|\n|   Michael|brown| null|\n|    Robert|  red|black|\n|Washington| grey| grey|\n| Jefferson|brown|     |\n+----------+-----+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.withColumn(\"hair\",df.properties[\"hair\"]) \\\n  .withColumn(\"eye\",df.properties[\"eye\"]) \\\n  .drop(\"properties\") \\\n  .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"bb2250ba-3eea-489a-a61e-b3b14e5d29d8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+-----+-----+\n|      name| hair|  eye|\n+----------+-----+-----+\n|     James|black|brown|\n|   Michael|brown| null|\n|    Robert|  red|black|\n|Washington| grey| grey|\n| Jefferson|brown|     |\n+----------+-----+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import explode\ndf.select(df.name,explode(df.properties)).show()\n\nfrom pyspark.sql.functions import map_keys\ndf.select(df.name,map_keys(df.properties)).show()\n\nfrom pyspark.sql.functions import map_values\ndf.select(df.name,map_values(df.properties)).show()\n\n#from pyspark.sql.functions import explode,map_keys\n#keysDF = df.select(explode(map_keys(df.properties))).distinct()\n#keysList = keysDF.rdd.map(lambda x:x[0]).collect()\n#print(keysList)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d2a6259a-5254-4ae5-bc37-165436a71018","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+----+-----+\n|      name| key|value|\n+----------+----+-----+\n|     James| eye|brown|\n|     James|hair|black|\n|   Michael| eye| null|\n|   Michael|hair|brown|\n|    Robert| eye|black|\n|    Robert|hair|  red|\n|Washington| eye| grey|\n|Washington|hair| grey|\n| Jefferson| eye|     |\n| Jefferson|hair|brown|\n+----------+----+-----+\n\n+----------+--------------------+\n|      name|map_keys(properties)|\n+----------+--------------------+\n|     James|         [eye, hair]|\n|   Michael|         [eye, hair]|\n|    Robert|         [eye, hair]|\n|Washington|         [eye, hair]|\n| Jefferson|         [eye, hair]|\n+----------+--------------------+\n\n+----------+----------------------+\n|      name|map_values(properties)|\n+----------+----------------------+\n|     James|        [brown, black]|\n|   Michael|         [null, brown]|\n|    Robert|          [black, red]|\n|Washington|          [grey, grey]|\n| Jefferson|             [, brown]|\n+----------+----------------------+\n\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-maptype-dataframe-column 2023-06-14 23:06:34","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
