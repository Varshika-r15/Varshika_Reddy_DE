{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# Create SparkSession\nspark = SparkSession.builder \\\n          .appName('SparkByExamples.com') \\\n          .getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c7bc3017-ab7b-4362-8190-3c11543d63ee","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["data = [(1,10),(2,20),(3,10),(4,20),(5,10),\n    (6,30),(7,50),(8,50),(9,50),(10,30),\n    (11,10),(12,10),(13,40),(14,40),(15,40),\n    (16,40),(17,50),(18,10),(19,40),(20,40)\n  ]\n\ndf=spark.createDataFrame(data,[\"id\",\"value\"])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6f891682-7199-48f3-a2ff-f77c97d0af9a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.repartition(3, \"value\").explain(True)\ndf.repartition(\"value\") \\\n    .write.option(\"header\", True) \\\n    .mode(\"overwrite\") \\\n    .csv(\"file:///tmp/range-partition\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a9f61266-a9ef-412f-87ee-daf87817556a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["== Parsed Logical Plan ==\n'RepartitionByExpression ['value], 3\n+- LogicalRDD [id#891L, value#892L], false\n\n== Analyzed Logical Plan ==\nid: bigint, value: bigint\nRepartitionByExpression [value#892L], 3\n+- LogicalRDD [id#891L, value#892L], false\n\n== Optimized Logical Plan ==\nRepartitionByExpression [value#892L], 3\n+- LogicalRDD [id#891L, value#892L], false\n\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Exchange hashpartitioning(value#892L, 3), REPARTITION_BY_NUM, [plan_id=1091]\n   +- Scan ExistingRDD[id#891L,value#892L]\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.repartitionByRange(\"value\").explain(True)\ndf.repartitionByRange(3, \"value\").explain(True)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2a2cc4c9-0eb5-4a97-bd14-5e9af108aa56","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["== Parsed Logical Plan ==\n'RepartitionByExpression ['value ASC NULLS FIRST]\n+- LogicalRDD [id#891L, value#892L], false\n\n== Analyzed Logical Plan ==\nid: bigint, value: bigint\nRepartitionByExpression [value#892L ASC NULLS FIRST]\n+- LogicalRDD [id#891L, value#892L], false\n\n== Optimized Logical Plan ==\nRepartitionByExpression [value#892L ASC NULLS FIRST]\n+- LogicalRDD [id#891L, value#892L], false\n\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Exchange rangepartitioning(value#892L ASC NULLS FIRST, 200), REPARTITION_BY_COL, [plan_id=1162]\n   +- Scan ExistingRDD[id#891L,value#892L]\n\n== Parsed Logical Plan ==\n'RepartitionByExpression ['value ASC NULLS FIRST], 3\n+- LogicalRDD [id#891L, value#892L], false\n\n== Analyzed Logical Plan ==\nid: bigint, value: bigint\nRepartitionByExpression [value#892L ASC NULLS FIRST], 3\n+- LogicalRDD [id#891L, value#892L], false\n\n== Optimized Logical Plan ==\nRepartitionByExpression [value#892L ASC NULLS FIRST], 3\n+- LogicalRDD [id#891L, value#892L], false\n\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Exchange rangepartitioning(value#892L ASC NULLS FIRST, 3), REPARTITION_BY_NUM, [plan_id=1186]\n   +- Scan ExistingRDD[id#891L,value#892L]\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.repartitionByRange(3, \"value\") \\\n    .write.option(\"header\", True) \\\n    .mode(\"overwrite\") \\\n    .csv(\"file:///tmp/range-partition-count\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"218a8852-31c2-420a-92bf-cad542291207","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-range-partition 2023-06-15 23:05:53","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
