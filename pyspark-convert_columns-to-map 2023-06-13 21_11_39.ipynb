{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1a61cec5-4415-4496-879b-37c13709cc15","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["data = [ (\"36636\",\"Finance\",3000,\"USA\"), \n    (\"40288\",\"Finance\",5000,\"IND\"), \n    (\"42114\",\"Sales\",3900,\"USA\"), \n    (\"39192\",\"Marketing\",2500,\"CAN\"), \n    (\"34534\",\"Sales\",6500,\"USA\") ]\nschema = StructType([\n     StructField('id', StringType(), True),\n     StructField('dept', StringType(), True),\n     StructField('salary', IntegerType(), True),\n     StructField('location', StringType(), True)\n     ])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8b3b5fb8-487f-4622-bbba-ae33da482b38","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.createDataFrame(data=data,schema=schema)\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c9d6806b-db5c-431d-85b7-2af4296589d2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- id: string (nullable = true)\n |-- dept: string (nullable = true)\n |-- salary: integer (nullable = true)\n |-- location: string (nullable = true)\n\n+-----+---------+------+--------+\n|id   |dept     |salary|location|\n+-----+---------+------+--------+\n|36636|Finance  |3000  |USA     |\n|40288|Finance  |5000  |IND     |\n|42114|Sales    |3900  |USA     |\n|39192|Marketing|2500  |CAN     |\n|34534|Sales    |6500  |USA     |\n+-----+---------+------+--------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Convert scolumns to Map\nfrom pyspark.sql.functions import col,lit,create_map\ndf = df.withColumn(\"propertiesMap\",create_map(\n        lit(\"salary\"),col(\"salary\"),\n        lit(\"location\"),col(\"location\")\n        )).drop(\"salary\",\"location\")\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1c138309-d342-49fa-a82b-00e808078eea","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- id: string (nullable = true)\n |-- dept: string (nullable = true)\n |-- propertiesMap: map (nullable = false)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+-----+---------+---------------------------------+\n|id   |dept     |propertiesMap                    |\n+-----+---------+---------------------------------+\n|36636|Finance  |{salary -> 3000, location -> USA}|\n|40288|Finance  |{salary -> 5000, location -> IND}|\n|42114|Sales    |{salary -> 3900, location -> USA}|\n|39192|Marketing|{salary -> 2500, location -> CAN}|\n|34534|Sales    |{salary -> 6500, location -> USA}|\n+-----+---------+---------------------------------+\n\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-convert_columns-to-map 2023-06-13 21:11:39","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
