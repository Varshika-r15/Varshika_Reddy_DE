{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import explode, flatten\n\n\nspark = SparkSession.builder.appName('pyspark-by-examples').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"5ca7b94d-3fcb-4b38-955e-312f6630e463","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["arrayArrayData = [\n  (\"James\",[[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"]]),\n  (\"Michael\",[[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"]]),\n  (\"Robert\",[[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"]])\n]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f1e05101-f60a-462d-8c13-2ef1b664274f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.createDataFrame(data=arrayArrayData, schema = ['name','subjects'])\ndf.printSchema()\ndf.show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"25238461-82af-4882-ac28-dbc0aaaa1be9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- name: string (nullable = true)\n |-- subjects: array (nullable = true)\n |    |-- element: array (containsNull = true)\n |    |    |-- element: string (containsNull = true)\n\n+-------+-----------------------------------+\n|name   |subjects                           |\n+-------+-----------------------------------+\n|James  |[[Java, Scala, C++], [Spark, Java]]|\n|Michael|[[Spark, Java, C++], [Spark, Java]]|\n|Robert |[[CSharp, VB], [Spark, Python]]    |\n+-------+-----------------------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.select(df.name,explode(df.subjects)).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d17fb4cc-bb79-432b-be3d-f983905f48a5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+------------------+\n|name   |col               |\n+-------+------------------+\n|James  |[Java, Scala, C++]|\n|James  |[Spark, Java]     |\n|Michael|[Spark, Java, C++]|\n|Michael|[Spark, Java]     |\n|Robert |[CSharp, VB]      |\n|Robert |[Spark, Python]   |\n+-------+------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["\"\"\" creates a single array from an array of arrays. \"\"\"\ndf.select(df.name,flatten(df.subjects)).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0e291735-8a4a-41dd-9922-6722d33bc66e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+-------------------------------+\n|name   |flatten(subjects)              |\n+-------+-------------------------------+\n|James  |[Java, Scala, C++, Spark, Java]|\n|Michael|[Spark, Java, C++, Spark, Java]|\n|Robert |[CSharp, VB, Spark, Python]    |\n+-------+-------------------------------+\n\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-explode-nested-array 2023-06-13 22:50:05","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
